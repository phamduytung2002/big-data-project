version: "3"

services:
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: namenode
    restart: always
    ports:
      - 9870:9870
      - 9010:9000
    volumes:
      - hadoop_namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=test
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
    env_file:
      - ./hadoop.env


  datanode-1:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-1
    restart: always
    volumes:
      - hadoop_datanode-1:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
      CORE_CONF_fs_defaultFS: hdfs://namenode:9000
    env_file:
      - ./hadoop.env


  datanode-2:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-2
    restart: always
    volumes:
      - hadoop_datanode-2:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env


  datanode-3:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: datanode-3
    restart: always
    volumes:
      - hadoop_datanode-3:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env


  resourcemanager:
    image: bde2020/hadoop-resourcemanager:2.0.0-hadoop3.2.1-java8
    container_name: resourcemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870"
    env_file:
      - ./hadoop.env


  nodemanager1:
    image: bde2020/hadoop-nodemanager:2.0.0-hadoop3.2.1-java8
    container_name: nodemanager
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088"
    env_file:
      - ./hadoop.env


  historyserver:
    image: bde2020/hadoop-historyserver:2.0.0-hadoop3.2.1-java8
    container_name: historyserver
    restart: always
    environment:
      SERVICE_PRECONDITION: "namenode:9000 namenode:9870 resourcemanager:8088"
    volumes:
      - hadoop_historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env


  spark-master:
    image: phamduytung2002/spark-master
    container_name: spark-master
    depends_on:
      - namenode
      - datanode-1 
      - datanode-2
      - datanode-3
    ports:
      - "8080:8080"
      - "7077:7077"
      - "4040:4040"
    environment:
      - PYSPARK_PYTHON=/usr/bin/python3
      - INIT_DAEMON_STEP=setup_spark
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_MASTER_HOST=spark-master
      - CC=gcc
      - CXX=g++


  spark-worker-1:
    image: phamduytung2002/spark-worker
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - PYSPARK_PYTHON=/usr/bin/python3
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=3G
      - SPARK_DRIVER_MEMORY=3G


  spark-worker-2:
    image: phamduytung2002/spark-worker
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8082"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=3G
      - SPARK_DRIVER_MEMORY=3G
      

  spark-worker-3:
    image: phamduytung2002/spark-worker
    container_name: spark-worker-3
    depends_on:
      - spark-master
    ports:
      - "8083:8083"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - SPARK_WORKER_CORES=3
      - SPARK_WORKER_MEMORY=3G
      - SPARK_DRIVER_MEMORY=3G


  zookeeper:
    image: confluentinc/cp-zookeeper:5.1.0
    hostname: zookeeper
    container_name: zookeeper
    ports:
      - 2181:2181
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181


  kafka-1:
    image: confluentinc/cp-kafka:5.1.0
    hostname: kafka-1
    container_name: kafka-1
    ports:
      - 9092:9092
      - 29092:29092
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-1:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.request.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock


  kafka-2:
    image: confluentinc/cp-kafka:5.1.0
    hostname: kafka-2
    container_name: kafka-2
    ports:
      - 9093:9093
      - 29093:29093
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 2
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-2:9093,PLAINTEXT_HOST://localhost:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.request.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock


  kafka-3:
    image: confluentinc/cp-kafka:5.1.0
    hostname: kafka-3
    container_name: kafka-3
    ports:
      - 9094:9094
      - 29094:29094
    depends_on:
      - zookeeper
    environment:
      KAFKA_BROKER_ID: 3
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-3:9094,PLAINTEXT_HOST://localhost:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 2
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.request.logger=WARN"
      KAFKA_LOG4J_ROOT_LOGLEVEL: WARN
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock


  cassandra-node:
    image: cassandra:latest
    container_name: cassandra-node
    networks:
      - cassandra-net
    environment:
      - CASSANDRA_SEEDS=cassandra-node,cassandra2,cassandra3
    ports:
      - "9042:9042"
    volumes:
      - cassandra-node-data:/var/lib/cassandra

  cassandra2:
    image: cassandra:latest
    container_name: cassandra2
    networks:
      - cassandra-net
    environment:
      - CASSANDRA_SEEDS=cassandra-node,cassandra2,cassandra3
    ports:
      - "9043:9042"
    volumes:
      - cassandra2-data:/var/lib/cassandra

  cassandra3:
    image: cassandra:latest
    container_name: cassandra3
    networks:
      - cassandra-net
    environment:
      - CASSANDRA_SEEDS=cassandra-node,cassandra2,cassandra3
    ports:
      - "9044:9042"
    volumes:
      - cassandra3-data:/var/lib/cassandra



  spark-history-server:
      image: bde2020/spark-history-server:3.3.0-hadoop3.3
      container_name: spark-history-server
      depends_on:
        - spark-master
      ports:
        - "18081:18081"
      volumes:
        - /tmp/spark-events-local:/tmp/spark-events


networks:
  cassandra-net:
    driver: bridge


volumes:
  hadoop_namenode:
  hadoop_datanode-1:
  hadoop_datanode-2:
  hadoop_datanode-3:
  hadoop_historyserver:
  cassandra-node-data:
  cassandra2-data:
  cassandra3-data:

